---
layout:     post
title:      Very Deep Convolutional Networks for Large-Scale Image Recognition 文献阅读
category:   post
description: 讨论CNN网络结构深度对性能的影响
tags: 文献阅读 深度学习 计算机视觉 CNN
---
# Very Deep Convolutional Networks for Large-Scale Image Recognition 文献阅读
## 简介
这篇文章主要讨论CNN的深度对大规模图像识别的影响，同时使用了3*3的小卷积核，在ILSVRC-2014中获得了classification第二名和localization第一名的成绩。
## 网络结构
卷积层的感受野大小为3 * 3，步长为1。max-pooling层不是每一个卷积层后都有，共有五层，pooling的窗口大小为2 * 2。每一个权重层的激励都使用ReLU，并且网络结构中不包含局部响应归一化（Local Response Normalisation），因为作者发现这种处理并不会提高性能并且导致了更多地内存消耗。

作者试验了5种结构的卷积神经网络，他们的区别仅在于卷积层的个数，也就是CNN的深度。ABCDE五种网络结构的权重层个数从11到19，相应模型参数从1.3亿到1.4亿。由于较小的感受野大小，本文网络结构虽然深度很大，但并不比一些较浅层的结构参数多。

![Network-Arch](/images/very-deep-cnn/very_deep1.jpg)

两个连续的3 * 3卷积层其实相当于5 * 5的有效感受野，三个连续的3 * 3卷积层相当于7 * 7的感受野，之所以不直接使用一个较大的卷积层是由于以下两点原因：

1. 三个卷积层同时也引入了三次非线性校正，从而令决策函数更具判别性；
2. 相对直接使用7 * 7的卷积层减少了参数的数量，相当于在7 * 7卷积层上添加了正则； 

上述两点我认为也是这篇文章的中心思想，今年的在分类项目得到最佳的GoogLeNet实际也使用了相似的思想，即很深的网络（22层）及较小的卷积核（主要3 * 3，也包括1 * 1和5 * 5）。

## 训练
接下来再简单谈下训练部分。大部分设置都比较常规，同时也使用了在其他文章中获得较好效果的多尺度训练。多尺度训练使用了两种方法，第一种训练时取了固定的两个尺度，S=256和S=384，随机从缩放后的图像上截取224 * 224的图像块，分别训练两个模型。为了加速，S=384的模型由训练好的S=256模型初始化。第二种称为scale jittering，对每幅图像将较短边重采样到(256,512)之间的随机值，然后再截取图像块，这样一个单一的模型可以识别很多尺度的目标，实验证明scale jittering比固定尺度效果好很多。

整体的模型基于**Caffe**实现，在4块GPU上通过数据并行化完成训练，训练单个模型需要2到3周的时间。

![Result](/images/very-deep-cnn/very_deep2.jpg)

从上述实验结果可以看到本文的模型VGG超过了2012及2013年的最好结果，并且与今年的winner GoogLeNet效果相当。